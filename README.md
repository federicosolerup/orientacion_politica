# **AnÃ¡lisis de OrientaciÃ³n PolÃ­tica en Transcripciones con BERT**

Este proyecto implementa un pipeline completo de Procesamiento de Lenguaje Natural (PLN) para detectar orientaciÃ³n polÃ­tica (â€œizquierdaâ€ vs â€œderechaâ€) en fragmentos de texto provenientes de transcripciones. Se parte del preprocesamiento del corpus, extracciÃ³n de entidades, filtrado semÃ¡ntico, construcciÃ³n del dataset, y se finaliza con el fine-tuning de un modelo **BERT en espaÃ±ol** para clasificaciÃ³n binaria.

El trabajo estÃ¡ dividido en cuatro etapas principales, totalmente reproducibles.

---

## **ğŸ“Œ 1. Preprocesamiento del corpus**

* Se cargan las transcripciones clasificadas en carpetas:
  **`transcripciones/izquierda`**, **`transcripciones/derecha`**, **`transcripciones/neutral`**.
* Cada archivo se segmenta en frases usando reglas simples de puntuaciÃ³n.
* Se extraen entidades nombradas (PER, ORG, LOC) con **spaCy (es_core_news_sm)**.
* Se genera un archivo JSON por transcripciÃ³n con todas las frases procesadas y las entidades detectadas.

Salida principal de esta etapa:

```
/resultados/*.json
```

*(Referencia del cÃ³digo fuente: )*

---

## **ğŸ“Œ 2. AnÃ¡lisis de entidades y filtrado**

### **2.1 Frecuencias de entidades**

Se recorren todos los JSON para construir un ranking global de entidades mencionadas.
Esto genera:

```
entidades_frecuentes.csv
```

*(Referencia: )*

### **2.2 Limpieza del ranking**

Se filtran palabras irrelevantes, expresiones coloquiales y tÃ©rminos no alfabÃ©ticos.
Se conserva solo un top 100 de entidades polÃ­ticamente Ãºtiles:

```
entidades_top100_limpias.csv
```

*(Referencia: )*

### **2.3 Filtrado de frases relevantes**

Se recorren los JSON originales y se seleccionan solo las frases que contienen entidades relevantes del top 100. Se genera:

```
/resultados_filtrados/izquierda/*.json
/resultados_filtrados/derecha/*.json
/resultados_filtrados/neutral/*.json
```

Finalmente, se construye el dataset balanceado y listo para entrenamiento:

```
train_significativo.csv
```

*(Referencia: )*

---

## **ğŸ“Œ 3. Fine-tuning de BERT**

Se utiliza el modelo base:

```
dccuchile/bert-base-spanish-wwm-cased
```

El pipeline incluye:

* TokenizaciÃ³n
* Chunking automÃ¡tico para textos largos
* DivisiÃ³n train/test (80/20)
* Entrenamiento con mÃ©tricas: accuracy, precision, recall, F1
* Guardado del mejor modelo

Salida del modelo:

```
/modelo_finetuneado_significativo/
```

*(Referencia del cÃ³digo: )*

---

## **ğŸ“Œ 4. ClasificaciÃ³n de textos nuevos**

Con el modelo fine-tuneado se clasifica cada frase:

* Se chunkearon las frases largas igual que en el entrenamiento.
* Se calcula el score promedio por fragmento.
* Si score > 0.5 â†’ **â€œderechaâ€**, si no â†’ **â€œizquierdaâ€**.
* Se genera un JSON con:

  * etiqueta final
  * score promedio
  * detalle por frase

Salida:

```
/resultados_significativos/izquierda/*.json
/resultados_significativos/derecha/*.json
```

*(Referencia de implementaciÃ³n: )*

---

## **ğŸ“‚ Estructura del proyecto**

```
.
â”œâ”€â”€ transcripciones/
â”‚   â”œâ”€â”€ izquierda/
â”‚   â”œâ”€â”€ derecha/
â”‚   â””â”€â”€ neutral/
â”œâ”€â”€ resultados/
â”œâ”€â”€ resultados_filtrados/
â”œâ”€â”€ resultados_significativos/
â”œâ”€â”€ entidades_frecuentes.csv
â”œâ”€â”€ entidades_top100_limpias.csv
â”œâ”€â”€ train_significativo.csv
â”œâ”€â”€ modelo_finetuneado_significativo/
â”œâ”€â”€ PLN.ipynb
â”œâ”€â”€ PLN.pdf
â””â”€â”€ README.md
```

---

## **ğŸ“¦ InstalaciÃ³n**

```bash
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers datasets scikit-learn pandas ipywidgets spacy
python -m spacy download es_core_news_sm
```

---

## **â–¶ï¸ EjecuciÃ³n del pipeline**

1. Ejecutar el preprocesamiento completo (Parte 1)
2. Ejecutar anÃ¡lisis de entidades y filtrado (Parte 2)
3. Entrenar BERT (Parte 3)
4. Clasificar textos nuevos (Parte 4)

Cada secciÃ³n del notebook reproduce exactamente estos pasos.

---

## **ğŸ“Š Resultados esperados**

* MÃ¡s de **29.000 frases significativas** detectadas para entrenamiento.
* Clasificador BERT entrenado para detectar orientaciÃ³n polÃ­tica con mÃ©tricas sÃ³lidas.
* ExportaciÃ³n de resultados por archivo, con detalle de scores por frase.

---

## **ğŸ“˜ DocumentaciÃ³n tÃ©cnica**

El archivo PDF incluido contiene toda la explicaciÃ³n teÃ³rica y prÃ¡ctica del pipeline y sus fundamentos:

>

---

## **âœ”ï¸ Estado del proyecto**

âœ”ï¸ Pipeline completo
âœ”ï¸ Dataset generado
âœ”ï¸ Modelo BERT fine-tuneado
âœ”ï¸ ClasificaciÃ³n de transcripciones neutral
âœ”ï¸ CÃ³digo documentado
